{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# You should replace these 3 lines with the output in calibration step\n",
    "DIM=(768, 432)\n",
    "K=np.array([[559.5570240342355, 0.0, 399.2668277470481], [0.0, 569.4305514418312, 269.0848227696134], [0.0, 0.0, 1.0]])\n",
    "D=np.array([[-0.06102882844568303], [-0.6321857003065529], [2.0311417763083495], [-1.1833229519134025]])\n",
    "def undistort(img):\n",
    "    h,w = img.shape[:2]\n",
    "    map1, map2 = cv2.fisheye.initUndistortRectifyMap(K, D, np.eye(3), K, DIM, cv2.CV_16SC2)\n",
    "    undistorted_img = cv2.remap(img, map1, map2, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "    return undistorted_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread(\"Pictures/fisheye/fisheye.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade tensorflow-hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "mag_x=263\n",
    "mag_y=110\n",
    "w=250\n",
    "h=230\n",
    "\n",
    "cap = cv2.VideoCapture('rtsp://service:Init12345.@192.168.99.149:554/?h264')\n",
    "cap.set(cv2.CAP_PROP_BUFFERSIZE,0)\n",
    "x = 0\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    undframe = undistort(frame)\n",
    "    # Display the resulting frame\n",
    "    cropped = undframe[mag_y:mag_y+h, mag_x:mag_x+w]\n",
    "    cv2.imshow('frame',cropped)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kalibracja przed stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream z obróbka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cap = cv2.VideoCapture('rtsp://service:Init12345.@192.168.99.149:554/?h264')\n",
    "cap.set(cv2.CAP_PROP_BUFFERSIZE,0)\n",
    "colorLow = np.array([0, 0, 0])\n",
    "colorHigh = np.array([70, 70, 70])\n",
    "x = 0\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    # Display the resulting frame\n",
    "    frametest = undistort(frame)\n",
    "    binaryim = cv2.inRange(undistort(frame), colorLow, colorHigh)\n",
    "    _, contours, hierarchy = cv2.findContours(binaryim, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) != 0:\n",
    "        # find the biggest countour (c) by the area\n",
    "        c = max(contours, key = cv2.contourArea)\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        cropped = frametest[y:y+h, x:x+w]\n",
    "        pts1 = np.float32([[0,0],[w,0],[10,h],[w-15,h]])\n",
    "        pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])\n",
    "        M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "        dst = cv2.warpPerspective(cropped,M,(300,300))\n",
    "        cv2.imshow('frame',dst)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cv2.inRange(undistort(frame), colorLow, colorHigh)\n",
    "frametest = undistort(frame)\n",
    "_, contours, hierarchy = cv2.findContours(test, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnt = contours[10]\n",
    "if len(contours) != 0:\n",
    "    # find the biggest countour (c) by the area\n",
    "    c = max(contours, key = cv2.contourArea)\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "\n",
    "    # draw the biggest contour (c) in green\n",
    "    cv2.rectangle(frametest,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    cv2.drawContours(frametest, c, 0, (0,255,0), 3)\n",
    "cv2.imshow(\"..\",frametest)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"..\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wyciecie kulek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 12):\n",
    "    color = dst[270:295, 5+i*24:35+i*24]\n",
    "    cv2.imwrite(f'Pictures/magazyn/im10{i}.jpg', color)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sieć neuronowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q pyyaml h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q -U tf-hub-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(r\"C:\\Users\\Radek\\Pictures\\magazyn\\my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datadir = \"C:/Users/radzi/Pictures/magazyn/Input_Delta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
    "image_data = image_generator.flow_from_directory(str(Datadir), target_size=IMAGE_SHAPE, batch_size=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in image_data:\n",
    "  print(\"Image batch shape: \", image_batch.shape)\n",
    "  print(\"Label batch shape: \", label_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
    "                                         input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_batch = feature_extractor_layer(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_extractor_layer,\n",
    "  layers.Dense(image_data.num_classes)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(),\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollectBatchStats(tf.keras.callbacks.Callback):\n",
    "  def __init__(self):\n",
    "    self.batch_losses = []\n",
    "    self.batch_acc = []\n",
    "\n",
    "  def on_train_batch_end(self, batch, logs=None):\n",
    "    self.batch_losses.append(logs['loss'])\n",
    "    self.batch_acc.append(logs['acc'])\n",
    "    self.model.reset_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = np.ceil(image_data.samples/image_data.batch_size)\n",
    "\n",
    "batch_stats_callback = CollectBatchStats()\n",
    "\n",
    "history = model.fit_generator(image_data, epochs=8,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              callbacks = [batch_stats_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array([\"Czerwone\",\"Niebieskie\",\"Puste\", \"Zielone\",\"Żółte\"])\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_batch = model.predict(image_batch)\n",
    "predicted_id = np.argmax(predicted_batch, axis=-1)\n",
    "predicted_label_batch = class_names[predicted_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_id = np.argmax(label_batch, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,9))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "for n in range(30):\n",
    "  plt.subplot(6,5,n+1)\n",
    "  plt.imshow(image_batch[n])\n",
    "  color = \"green\" if predicted_id[n] == label_id[n] else \"red\"\n",
    "  plt.title(predicted_label_batch[n].title(), color=color)\n",
    "  plt.axis('off')\n",
    "_ = plt.suptitle(\"Model predictions (green: correct, red: incorrect)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r\"C:\\Users\\radzi\\Pictures\\magazyn\\my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(r\"C:\\Users\\radzi\\Pictures\\magazyn\\my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should replace these 3 lines with the output in calibration step\n",
    "DIM=(768, 432)\n",
    "K=np.array([[559.5570240342355, 0.0, 399.2668277470481], [0.0, 569.4305514418312, 269.0848227696134], [0.0, 0.0, 1.0]])\n",
    "D=np.array([[-0.06102882844568303], [-0.6321857003065529], [2.0311417763083495], [-1.1833229519134025]])\n",
    "def undistort(img):\n",
    "    h,w = img.shape[:2]\n",
    "    map1, map2 = cv2.fisheye.initUndistortRectifyMap(K, D, np.eye(3), K, DIM, cv2.CV_16SC2)\n",
    "    undistorted_img = cv2.remap(img, map1, map2, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "    return undistorted_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_x=255\n",
    "mag_y=130\n",
    "w=260\n",
    "h=250\n",
    "\n",
    "cap = cv2.VideoCapture('rtsp://service:Init12345.@192.168.99.149:554/?h264')\n",
    "#cap.set(cv2.CAP_PROP_BUFFERSIZE,0)\n",
    "\n",
    "# Capture frame-by-frame\n",
    "ret, frame = cap.read()\n",
    "undframe = undistort(frame)\n",
    "# Display the resulting frame\n",
    "cropped = undframe[mag_y:mag_y+h, mag_x:mag_x+w]\n",
    "image=cropped\n",
    "#image = cv2.circle(cropped, (5,15), 1, (0,250,0), 3)\n",
    "#image = cv2.circle(image, (256,21), 1, (0,250,0), 3)\n",
    "#image = cv2.circle(image, (235,235), 1, (0,250,0), 3)\n",
    "#image = cv2.circle(image, (20,235), 1, (0,250,0), 3)\n",
    "cv2.imshow('frame',image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspective Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts1 = np.float32([[5,15], [256,21], [20,235], [235,235]]) \n",
    "pts2 = np.float32([[0, 0], [300, 0], [0, 300], [300, 300]]) \n",
    "    \n",
    "# Apply Perspective Transform Algorithm \n",
    "matrix = cv2.getPerspectiveTransform(pts1, pts2) \n",
    "result = cv2.warpPerspective(image, matrix, (300, 300)) \n",
    "    \n",
    "cv2.imshow('frame',result)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color3 = []\n",
    "color2 = []\n",
    "x = []\n",
    "for i in range(0, 10):\n",
    "    color = result[275:300, 0+i*30:34+i*30]\n",
    "    color2.append(cv2.resize(color,(224,224)))\n",
    "    normalizedImg = np.zeros((224, 224))\n",
    "    normalizedImg = cv2.normalize(color2[i],  normalizedImg, 0, 255, cv2.NORM_MINMAX)\n",
    "    color3.append(np.expand_dims(color2[i], axis=0))\n",
    "    cv2.imwrite(f\"Pictures/magazyn/imtest/imtest{i}.jpg\",color2[i])\n",
    "    \n",
    "#im = cv2.imread(r\"C:\\Users\\Radek\\Pictures\\magazyn\\Imtest1.jpg\")\n",
    "#cv2.imshow('sss', im)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(r\"C:\\Users\\radzi\\Pictures\\magazyn\\my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wgranie pojedynczego zdjęcia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array([\"Czerwone\",\"Niebieskie\",\"Puste\", \"Zielone\",\"Żółte\"])\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Czerwone\",\"Niebieskie\",\"Puste\", \"Zielone\",\"Zolte\"\n",
    "kulka = \"Zielone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label_batch = []\n",
    "array_index = []\n",
    "for i in range(0, 10):\n",
    "    image = tf.keras.preprocessing.image.load_img(f\"Pictures/magazyn/imtest/imtest{i}.jpg\")\n",
    "    input_arr = keras.preprocessing.image.img_to_array(image)\n",
    "    norm_img = np.zeros((224,224))\n",
    "    input_arr = cv2.normalize(input_arr, norm_img, 1, 0,cv2.NORM_MINMAX);\n",
    "    input_arr = np.array([input_arr])\n",
    "    predicted_batch = reconstructed_model.predict(input_arr)\n",
    "    predicted_id = np.argmax(predicted_batch, axis=-1)\n",
    "    predicted_label_batch = class_names[predicted_id]\n",
    "    \n",
    "    if predicted_label_batch == kulka:\n",
    "        array_index = i\n",
    "        break\n",
    "    else:\n",
    "        array_index = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sys\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "pts1 = np.float32([[5,15], [256,21], [20,235], [235,235]]) \n",
    "pts2 = np.float32([[0, 0], [300, 0], [0, 300], [300, 300]]) \n",
    "kulka = \"Zielone\"\n",
    "\n",
    "# You should replace these 3 lines with the output in calibration step\n",
    "DIM=(768, 432)\n",
    "K=np.array([[559.5570240342355, 0.0, 399.2668277470481], [0.0, 569.4305514418312, 269.0848227696134], [0.0, 0.0, 1.0]])\n",
    "D=np.array([[-0.06102882844568303], [-0.6321857003065529], [2.0311417763083495], [-1.1833229519134025]])\n",
    "def undistort(img):\n",
    "    h,w = img.shape[:2]\n",
    "    map1, map2 = cv2.fisheye.initUndistortRectifyMap(K, D, np.eye(3), K, DIM, cv2.CV_16SC2)\n",
    "    undistorted_img = cv2.remap(img, map1, map2, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "    return undistorted_img\n",
    "mag_x=255\n",
    "mag_y=130\n",
    "w=260\n",
    "h=250\n",
    "reconstructed_model = keras.models.load_model(r\"C:\\Users\\radzi\\Pictures\\magazyn\\my_model\")\n",
    "class_names = np.array([\"Czerwone\",\"Niebieskie\",\"Puste\", \"Zielone\",\"Żółte\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('rtsp://service:Init12345.@192.168.99.149:554/?h264')\n",
    "#cap.set(cv2.CAP_PROP_BUFFERSIZE,0)\n",
    "\n",
    "# Capture frame-by-frame\n",
    "ret, frame = cap.read()\n",
    "undframe = undistort(frame)\n",
    "# Display the resulting frame\n",
    "cropped = undframe[mag_y:mag_y+h, mag_x:mag_x+w]\n",
    "image=cropped\n",
    "#image = cv2.circle(cropped, (5,15), 1, (0,250,0), 3)\n",
    "#image = cv2.circle(image, (256,21), 1, (0,250,0), 3)\n",
    "#image = cv2.circle(image, (235,235), 1, (0,250,0), 3)\n",
    "#image = cv2.circle(image, (20,235), 1, (0,250,0), 3)\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "# Apply Perspective Transform Algorithm \n",
    "matrix = cv2.getPerspectiveTransform(pts1, pts2) \n",
    "result = cv2.warpPerspective(image, matrix, (300, 300)) \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "color3 = []\n",
    "color2 = []\n",
    "x = []\n",
    "for i in range(0, 10):\n",
    "    color = result[275:300, 0+i*30:34+i*30]\n",
    "    color2.append(cv2.resize(color,(224,224)))\n",
    "    #cv2.imwrite(f\"Pictures/magazyn/imtest/imtest{i}.jpg\",color2[i])\n",
    "    \n",
    "predicted_label_batch = []\n",
    "array_index = []\n",
    "for i in range(0, 10):\n",
    "    #image = tf.keras.preprocessing.image.load_img(f\"Pictures/magazyn/imtest/imtest{i}.jpg\")\n",
    "    image = color2[i]\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = Image.fromarray(image)\n",
    "    input_arr = keras.preprocessing.image.img_to_array(image)\n",
    "    norm_img = np.zeros((224,224))\n",
    "    input_arr = cv2.normalize(input_arr, norm_img, 1, 0,cv2.NORM_MINMAX);\n",
    "    input_arr = np.array([input_arr])\n",
    "    predicted_batch = reconstructed_model.predict(input_arr)\n",
    "    predicted_id = np.argmax(predicted_batch, axis=-1)\n",
    "    predicted_label_batch = class_names[predicted_id]\n",
    "    \n",
    "    if predicted_label_batch == kulka:\n",
    "        array_index = i\n",
    "        break\n",
    "    else:\n",
    "        array_index = \"None\"\n",
    "#sys.exit(array_index)\n",
    "print(array_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Puste'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = np.array([\"Czerwone\",\"Niebieskie\",\"Puste\", \"Zielone\",\"Żółte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
